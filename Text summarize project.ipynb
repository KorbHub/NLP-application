{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "900fa86e",
   "metadata": {},
   "source": [
    "<b>Text summarization project<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2c23a0",
   "metadata": {},
   "source": [
    "Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning.\n",
    "\n",
    "Text summarization mean producing a concise and fluent summary without deleting the key information and overall meaning.\n",
    "\n",
    "The summarization methods can be applied in the business such as summarize finanical news to find the impact headline and information, as well as in the scientific such as summarizing research paper information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78a9966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy>=1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a855f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful variable\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e304179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to read the article\n",
    "# Here note that we will read the sentence in the from of txt file \n",
    "def read_article(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    filedata = file.readlines() # read everyline of the data \n",
    "    article = filedata[0].split(\". \")\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in article:\n",
    "        print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f2c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to build the sentence similarlity matrix\n",
    "# changing each sentence to the represent vector \n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "# score the similarlity score in each matrix\n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "181e55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(file_name, top_n=5):\n",
    "    nltk.download(\"stopwords\")\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    #split the sumart \n",
    "    sentences =  read_article(file_name)\n",
    "\n",
    "    # generate similarity matrix \n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # rank sentence based on it similarity \n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    #pick only the top sentence \n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    #output the summary text\n",
    "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4582332b",
   "metadata": {},
   "source": [
    "Note for the further improvement of the project, we can optimize how we select the number of the sentence to summarize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e5dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
